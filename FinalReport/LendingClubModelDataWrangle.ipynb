{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LendingClub Data Statistical Analysis\n",
    "# Two sources of data and a data dictionary\n",
    "# Data in CSV and SQL files are provided - Kaggle\n",
    "# Looks like FICO score data is missing and some column names are different\n",
    "import math\n",
    "import sqlite3\n",
    "import csv\n",
    "import pandas as pd\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from dateutil.parser import parse\n",
    "from datetime import datetime\n",
    "from statsmodels.stats import weightstats as stests\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "from matplotlib import rcParams\n",
    "rcParams.update({'figure.autolayout': True})\n",
    "\n",
    "dataURL = 'https://www.kaggle.com/wendykan/lending-club-loan-data/downloads/lending-club-loan-data.zip'\n",
    "homeDir = \"/fdata/LendingClub/lending-club-loan-data/\"\n",
    "fnSQL = \"database.sqlite\"\n",
    "fnCSV = \"loan.csv\"\n",
    "\n",
    "# list of sub grade categories\n",
    "sg = ['A1','A2','A3','A4','A5',\\\n",
    "      'B1','B2','B3','B4','B5',\\\n",
    "      'C1','C2','C3','C4','C5',\\\n",
    "      'D1','D2','D3','D4','D5',\\\n",
    "      'E1','E3','E3','E4','E5',\\\n",
    "      'F1','F2','F3','F4','F5',\\\n",
    "      'G1','G2','G3','G4','G5']\n",
    "\n",
    "# read in column names from loan.csv\n",
    "with open(homeDir+fnCSV) as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter='\\t')\n",
    "    cnCSV = next(reader)[0].split(',')\n",
    "#print(len(cnCSV))\n",
    "#print(cnCSV)\n",
    "# 74 Data Columns\n",
    "\n",
    "# get column of data from CSV file\n",
    "def getCSVColumn(header):\n",
    "    try:\n",
    "        indx = cnCSV.index(header)\n",
    "        with open(homeDir+fnCSV) as csvfile:\n",
    "            reader = csv.reader(csvfile)\n",
    "            tcol = list(zip(*reader))[indx]\n",
    "            col = list(tcol)\n",
    "            col.pop(0)\n",
    "            return col\n",
    "    except ValueError:\n",
    "        print(\"Column not found:\", header)\n",
    "        col = []\n",
    "        return col\n",
    "\n",
    "# get column of data from SQLite file\n",
    "def getSQLiteColumn(header):\n",
    "    col = []\n",
    "    conn = sqlite3.connect(homeDir+fnSQL)\n",
    "    cursor = conn.execute('SELECT ' + header + ' FROM loan')\n",
    "    for row in cursor.fetchall():\n",
    "        col.append(row[0])\n",
    "    return col\n",
    "\n",
    "# statistical KS comparison of factor across sub grades\n",
    "# test distributions are the same of factor in columns 10 sub-grade (2 grades) apart\n",
    "def slidingKSTest(subgrade, factor, space):\n",
    "    p = np.zeros(shape=(35 - space))\n",
    "    for i in range(35 - space):\n",
    "        s1 = sg[i]\n",
    "        s2 = sg[i+space]\n",
    "        t1 = []\n",
    "        t2 = []\n",
    "        for indx, entry in enumerate(subgrade):\n",
    "            if entry == s1:\n",
    "                if not math.isnan(factor[indx]):\n",
    "                    t1.append(factor[indx])\n",
    "            if entry == s2:\n",
    "                if not math.isnan(factor[indx]):\n",
    "                    t2.append(factor[indx])\n",
    "        #print(len(t1),len(t2))\n",
    "        a, b = ks_2samp(t1,t2)\n",
    "        p[i] = b\n",
    "    return p\n",
    "\n",
    "# Statistical KS comparison between A grade and factor from all other sub-grades\n",
    "# test 'distributions are the same'\n",
    "def slidingAGrade_KSTest(subgrade, factor):\n",
    "    p = np.zeros(shape=(30))\n",
    "    for i in range(30):\n",
    "        s1 = 'A'\n",
    "        s2 = sg[i+5]\n",
    "        t1 = []\n",
    "        t2 = []\n",
    "        for indx, entry in enumerate(subgrade):\n",
    "            if entry[0:1] == s1:\n",
    "                if not math.isnan(factor[indx]):\n",
    "                    t1.append(factor[indx])\n",
    "            if entry == s2:\n",
    "                if not math.isnan(factor[indx]):\n",
    "                    t2.append(factor[indx])\n",
    "        #print(len(t1),len(t2))\n",
    "        a, b = ks_2samp(t1,t2)\n",
    "        p[i] = b\n",
    "    return p\n",
    "\n",
    "# Compare default/charge off to paid off\n",
    "def compareGB(subgrade, status, factor,fname):\n",
    "    fg = []\n",
    "    sgg = []\n",
    "    fb = []\n",
    "    sgb = []\n",
    "    for indx, entry in enumerate(status):\n",
    "        if (entry == 'Fully Paid'):\n",
    "            if not math.isnan(factor[indx]):\n",
    "                fg.append(factor[indx])\n",
    "                sgg.append(subgrade[indx]+'G')\n",
    "        elif ((entry == 'Charged Off') | (entry == 'Default')):\n",
    "            if not math.isnan(factor[indx]):\n",
    "                fb.append(factor[indx])\n",
    "                sgb.append(subgrade[indx]+'B')         \n",
    "    gdf = pd.DataFrame(list(zip(sgg,fg)),columns=['Sub Grade',fname])\n",
    "    bdf = pd.DataFrame(list(zip(sgb,fb)),columns=['Sub Grade',fname])\n",
    "    return gdf, bdf\n",
    "\n",
    "# Compare Bad/Good Loans using KS test\n",
    "# each subgrade\n",
    "# each total population\n",
    "def GBKSTest(subgrade, status,factor,fname):\n",
    "    good, bad = compareGB(subgrade,status,factor,fname)\n",
    "    KSs = []\n",
    "    for indx, entry in enumerate(sg):\n",
    "        gn = good.loc[good['Sub Grade'] == entry+'G'][fname].tolist()\n",
    "        bn =  bad.loc[bad['Sub Grade'] == entry+'B'][fname].tolist()\n",
    "        a, b = ks_2samp(gn,bn)\n",
    "        KSs.append(b)\n",
    "    gna = good[fname].tolist()\n",
    "    bna = bad[fname].tolist()\n",
    "    a, KSa = ks_2samp(gna,bna)\n",
    "    return KSs, KSa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load columns used for fitting from sql file and compare to ones from csv source\n",
    "grablist_sql = ['id','loan_status','dti','revol_bal','acc_now_delinq','collections_12_mths_ex_med','delinq_2yrs',\\\n",
    "            'emp_length','inq_last_6mths','inq_fi','il_util','earliest_cr_line','annual_inc','revol_util',\\\n",
    "            'open_acc','tot_coll_amt','verification_status']\n",
    "dcheck_sql = pd.DataFrame()\n",
    "for entry in grablist_sql:\n",
    "    temp = pd.DataFrame(getSQLiteColumn(entry))\n",
    "    dcheck_sql = pd.concat([dcheck_sql, temp], axis=1)\n",
    "dcheck_sql.columns = grablist_sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "grablist_csv = ['id','loan_status','dti','revol_bal','acc_now_delinq','collections_12_mths_ex_med','delinq_2yrs',\\\n",
    "            'emp_length','inq_last_6mths','inq_fi','il_util','earliest_cr_line','annual_inc','revol_util',\\\n",
    "            'open_acc','tot_coll_amt','verification_status']\n",
    "dcheck_csv = pd.DataFrame()\n",
    "for entry in grablist_csv:\n",
    "    temp = pd.DataFrame(getCSVColumn(entry))\n",
    "    dcheck_csv = pd.concat([dcheck_csv, temp], axis=1)\n",
    "dcheck_csv.columns = grablist_sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle them\n",
    "dcheck_sql.to_pickle(homeDir+'DCheckSQL.pkl')\n",
    "dcheck_csv.to_pickle(homeDir+'DCheckCSV.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcheck_sql = pd.read_pickle(homeDir+'DCheckSQL.pkl')\n",
    "dcheck_csv = pd.read_pickle(homeDir+'DCheckCSV.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# do a bunch of data processing for both data frames\n",
    "from dateutil.parser import parse\n",
    "from datetime import datetime\n",
    "dcheck_csv = dcheck_csv.replace(r'', np.nan, regex=True)\n",
    "# Income Verification to numeric code\n",
    "dcheck_csv.loc[dcheck_csv['verification_status'] == 'Not Verified', 'IVCode'] = 0\n",
    "dcheck_csv.loc[dcheck_csv['verification_status'] == 'Source Verified', 'IVCode'] = 1\n",
    "dcheck_csv.loc[dcheck_csv['verification_status'] == 'Verified', 'IVCode'] = 2\n",
    "dcheck_sql.loc[dcheck_sql['verification_status'] == 'Not Verified', 'IVCode'] = 0\n",
    "dcheck_sql.loc[dcheck_sql['verification_status'] == 'Source Verified', 'IVCode'] = 1\n",
    "dcheck_sql.loc[dcheck_sql['verification_status'] == 'Verified', 'IVCode'] = 2\n",
    "# Loan Status to numeric code\n",
    "# Only use default, charged off (bad) and fully paid (good)\n",
    "dcheck_csv.loc[(dcheck_csv['loan_status'] == 'Fully Paid') | \\\n",
    "          (dcheck_csv['loan_status'] == 'Does not meet the credit policy. Status:Fully Paid'),'LSCode'] = 0\n",
    "dcheck_csv.loc[(dcheck_csv['loan_status'] == 'Charged Off') | (dcheck_csv['loan_status'] == 'Default') | \\\n",
    "          (dcheck_csv['loan_status'] == 'Does not meet the credit policy. Status:Charged Off'),'LSCode'] = 1\n",
    "dcheck_sql.loc[(dcheck_sql['loan_status'] == 'Fully Paid') | \\\n",
    "          (dcheck_sql['loan_status'] == 'Does not meet the credit policy. Status:Fully Paid'),'LSCode'] = 0\n",
    "dcheck_sql.loc[(dcheck_sql['loan_status'] == 'Charged Off') | (dcheck_sql['loan_status'] == 'Default') | \\\n",
    "          (dcheck_sql['loan_status'] == 'Does not meet the credit policy. Status:Charged Off'),'LSCode'] = 1\n",
    "# convert years employed to code\n",
    "dcheck_csv.loc[dcheck_csv['emp_length'] == '10+ years','ELCode'] = 10.0\n",
    "dcheck_csv.loc[dcheck_csv['emp_length'] == '< 1 year','ELCode'] = 0.5\n",
    "dcheck_csv.loc[dcheck_csv['emp_length'] == '3 years','ELCode'] = 3.0\n",
    "dcheck_csv.loc[dcheck_csv['emp_length'] == '9 years','ELCode'] = 9.0\n",
    "dcheck_csv.loc[dcheck_csv['emp_length'] == '4 years','ELCode'] = 4.0\n",
    "dcheck_csv.loc[dcheck_csv['emp_length'] == '5 years','ELCode'] = 5.0\n",
    "dcheck_csv.loc[dcheck_csv['emp_length'] == '1 year','ELCode'] = 1.0\n",
    "dcheck_csv.loc[dcheck_csv['emp_length'] == '6 years','ELCode'] = 6.0\n",
    "dcheck_csv.loc[dcheck_csv['emp_length'] == '2 years','ELCode'] = 2.0\n",
    "dcheck_csv.loc[dcheck_csv['emp_length'] == '7 years','ELCode'] = 7.0\n",
    "dcheck_csv.loc[dcheck_csv['emp_length'] == '8 years','ELCode'] = 8.0\n",
    "dcheck_csv.loc[dcheck_csv['emp_length'] == 'n/a','ELCode'] = np.nan\n",
    "dcheck_sql.loc[dcheck_sql['emp_length'] == '10+ years','ELCode'] = 10.0\n",
    "dcheck_sql.loc[dcheck_sql['emp_length'] == '< 1 year','ELCode'] = 0.5\n",
    "dcheck_sql.loc[dcheck_sql['emp_length'] == '3 years','ELCode'] = 3.0\n",
    "dcheck_sql.loc[dcheck_sql['emp_length'] == '9 years','ELCode'] = 9.0\n",
    "dcheck_sql.loc[dcheck_sql['emp_length'] == '4 years','ELCode'] = 4.0\n",
    "dcheck_sql.loc[dcheck_sql['emp_length'] == '5 years','ELCode'] = 5.0\n",
    "dcheck_sql.loc[dcheck_sql['emp_length'] == '1 year','ELCode'] = 1.0\n",
    "dcheck_sql.loc[dcheck_sql['emp_length'] == '6 years','ELCode'] = 6.0\n",
    "dcheck_sql.loc[dcheck_sql['emp_length'] == '2 years','ELCode'] = 2.0\n",
    "dcheck_sql.loc[dcheck_sql['emp_length'] == '7 years','ELCode'] = 7.0\n",
    "dcheck_sql.loc[dcheck_sql['emp_length'] == '8 years','ELCode'] = 8.0\n",
    "dcheck_sql.loc[dcheck_sql['emp_length'] == 'n/a','ELCode'] = np.nan\n",
    "#convert earliest credit to number of days\n",
    "ec_csv = dcheck_csv['earliest_cr_line'].tolist()\n",
    "for indx, element in enumerate(ec_csv):\n",
    "    if (element != '') & (isinstance(element,str)):\n",
    "        ec_csv[indx] = (parse('Jan-2016') - parse(element)).days\n",
    "    else:\n",
    "        ec_csv[indx] = np.nan\n",
    "        \n",
    "ec_sql = dcheck_sql['earliest_cr_line'].tolist()\n",
    "for indx, element in enumerate(ec_sql):\n",
    "    if (element != '') & (isinstance(element,str)):\n",
    "        ec_sql[indx] = (parse('Jan-2016') - parse(element)).days\n",
    "    else:\n",
    "        ec_sql[indx] = np.nan\n",
    "        \n",
    "dcheck_csv['ECDays'] = pd.DataFrame(ec_csv,columns=['ECDays'])\n",
    "dcheck_sql['ECDays'] = pd.DataFrame(ec_sql,columns=['ECDays'])\n",
    "del dcheck_csv['earliest_cr_line']\n",
    "del dcheck_sql['earliest_cr_line']\n",
    "del dcheck_csv['emp_length']\n",
    "del dcheck_sql['emp_length']\n",
    "del dcheck_sql['loan_status']\n",
    "del dcheck_csv['loan_status']\n",
    "del dcheck_sql['verification_status']\n",
    "del dcheck_csv['verification_status']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                              int64\n",
      "dti                           float64\n",
      "revol_bal                     float64\n",
      "acc_now_delinq                float64\n",
      "collections_12_mths_ex_med    float64\n",
      "delinq_2yrs                   float64\n",
      "inq_last_6mths                float64\n",
      "inq_fi                        float64\n",
      "il_util                       float64\n",
      "annual_inc                    float64\n",
      "revol_util                    float64\n",
      "open_acc                      float64\n",
      "tot_coll_amt                  float64\n",
      "IVCode                        float64\n",
      "LSCode                        float64\n",
      "ELCode                        float64\n",
      "ECDays                        float64\n",
      "dtype: object\n",
      "id                            float64\n",
      "dti                           float64\n",
      "revol_bal                     float64\n",
      "acc_now_delinq                float64\n",
      "collections_12_mths_ex_med    float64\n",
      "delinq_2yrs                   float64\n",
      "inq_last_6mths                float64\n",
      "inq_fi                        float64\n",
      "il_util                       float64\n",
      "annual_inc                    float64\n",
      "revol_util                    float64\n",
      "open_acc                      float64\n",
      "tot_coll_amt                  float64\n",
      "IVCode                        float64\n",
      "LSCode                        float64\n",
      "ELCode                        float64\n",
      "ECDays                        float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "tnum = ['id','dti','revol_bal','acc_now_delinq','collections_12_mths_ex_med','delinq_2yrs','inq_last_6mths',\\\n",
    "       'inq_fi','il_util','annual_inc','open_acc','tot_coll_amt']\n",
    "dcheck_csv[tnum] = dcheck_csv[tnum].apply(pd.to_numeric,errors='coerce')\n",
    "dcheck_sql['id'] = dcheck_sql['id'].apply(pd.to_numeric,errors='coerce')\n",
    "dcheck_csv['revol_util'] = dcheck_csv['revol_util'].apply(pd.to_numeric,errors='coerce')\n",
    "dcheck_sql['revol_util'] = dcheck_sql['revol_util'].map(lambda x: str(x)[:-1])\n",
    "dcheck_sql['revol_util'] = dcheck_sql['revol_util'].apply(pd.to_numeric,errors='coerce')\n",
    "print(dcheck_csv.dtypes)\n",
    "print(dcheck_sql.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle them\n",
    "dcheck_sql.to_pickle(homeDir+'DCheckSQL_F.pkl')\n",
    "dcheck_csv.to_pickle(homeDir+'DCheckCSV_F.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id    dti  revol_bal  acc_now_delinq  collections_12_mths_ex_med  \\\n",
      "0  1077501  27.65    13648.0             0.0                         0.0   \n",
      "1  1077430   1.00     1687.0             0.0                         0.0   \n",
      "2  1077175   8.72     2956.0             0.0                         0.0   \n",
      "3  1076863  20.00     5598.0             0.0                         0.0   \n",
      "4  1075358  17.94    27783.0             0.0                         0.0   \n",
      "\n",
      "   delinq_2yrs  inq_last_6mths  annual_inc  revol_util  open_acc  IVCode  \\\n",
      "0          0.0             1.0     24000.0        83.7       3.0     2.0   \n",
      "1          0.0             5.0     30000.0         9.4       3.0     1.0   \n",
      "2          0.0             2.0     12252.0        98.5       2.0     0.0   \n",
      "3          0.0             1.0     49200.0        21.0      10.0     1.0   \n",
      "4          0.0             0.0     80000.0        53.9      15.0     1.0   \n",
      "\n",
      "   LSCode  ELCode   ECDays  \n",
      "0     0.0    10.0  11322.0  \n",
      "1     1.0     0.5   6119.0  \n",
      "2     0.0    10.0   5174.0  \n",
      "3     0.0    10.0   7274.0  \n",
      "4     NaN     1.0   7305.0  \n",
      "id                            246593\n",
      "dti                           246593\n",
      "revol_bal                     246593\n",
      "acc_now_delinq                246593\n",
      "collections_12_mths_ex_med    246593\n",
      "delinq_2yrs                   246593\n",
      "inq_last_6mths                246593\n",
      "annual_inc                    246593\n",
      "revol_util                    246593\n",
      "open_acc                      246593\n",
      "IVCode                        246593\n",
      "LSCode                        246593\n",
      "ELCode                        246593\n",
      "ECDays                        246593\n",
      "dtype: int64\n",
      "id                            246592\n",
      "dti                           246592\n",
      "revol_bal                     246592\n",
      "acc_now_delinq                246592\n",
      "collections_12_mths_ex_med    246592\n",
      "delinq_2yrs                   246592\n",
      "inq_last_6mths                246592\n",
      "annual_inc                    246592\n",
      "revol_util                    246592\n",
      "open_acc                      246592\n",
      "IVCode                        246592\n",
      "LSCode                        246592\n",
      "ELCode                        246592\n",
      "ECDays                        246592\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dcheck_sql = pd.read_pickle(homeDir+'DCheckSQL_F.pkl')\n",
    "dcheck_csv = pd.read_pickle(homeDir+'DCheckCSV_F.pkl')\n",
    "del dcheck_sql['inq_fi']\n",
    "del dcheck_sql['il_util']\n",
    "del dcheck_sql['tot_coll_amt']\n",
    "del dcheck_csv['inq_fi']\n",
    "del dcheck_csv['il_util']\n",
    "del dcheck_csv['tot_coll_amt']\n",
    "print(dcheck_csv.head())\n",
    "dcheck_sql.dropna(inplace=True)\n",
    "dcheck_csv.dropna(inplace=True)\n",
    "print(dcheck_sql.count())\n",
    "print(dcheck_csv.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id    dti  revol_bal  acc_now_delinq  collections_12_mths_ex_med  \\\n",
      "0  1077501  27.65    13648.0             0.0                         0.0   \n",
      "1  1077430   1.00     1687.0             0.0                         0.0   \n",
      "2  1077175   8.72     2956.0             0.0                         0.0   \n",
      "3  1076863  20.00     5598.0             0.0                         0.0   \n",
      "5  1075269  11.20     7963.0             0.0                         0.0   \n",
      "\n",
      "   delinq_2yrs  inq_last_6mths  annual_inc  revol_util  open_acc  IVCode  \\\n",
      "0          0.0             1.0     24000.0        83.7       3.0     2.0   \n",
      "1          0.0             5.0     30000.0         9.4       3.0     1.0   \n",
      "2          0.0             2.0     12252.0        98.5       2.0     0.0   \n",
      "3          0.0             1.0     49200.0        21.0      10.0     1.0   \n",
      "5          0.0             3.0     36000.0        28.3       9.0     1.0   \n",
      "\n",
      "   LSCode  ELCode   ECDays  \n",
      "0     0.0    10.0  11322.0  \n",
      "1     1.0     0.5   6119.0  \n",
      "2     0.0    10.0   5174.0  \n",
      "3     0.0    10.0   7274.0  \n",
      "5     0.0     3.0   4078.0  \n",
      "          id    dti  revol_bal  acc_now_delinq  collections_12_mths_ex_med  \\\n",
      "0  1077501.0  27.65    13648.0             0.0                         0.0   \n",
      "1  1077430.0   1.00     1687.0             0.0                         0.0   \n",
      "2  1077175.0   8.72     2956.0             0.0                         0.0   \n",
      "3  1076863.0  20.00     5598.0             0.0                         0.0   \n",
      "5  1075269.0  11.20     7963.0             0.0                         0.0   \n",
      "\n",
      "   delinq_2yrs  inq_last_6mths  annual_inc  revol_util  open_acc  IVCode  \\\n",
      "0          0.0             1.0     24000.0        83.7       3.0     2.0   \n",
      "1          0.0             5.0     30000.0         9.4       3.0     1.0   \n",
      "2          0.0             2.0     12252.0        98.5       2.0     0.0   \n",
      "3          0.0             1.0     49200.0        21.0      10.0     1.0   \n",
      "5          0.0             3.0     36000.0        28.3       9.0     1.0   \n",
      "\n",
      "   LSCode  ELCode   ECDays  \n",
      "0     0.0    10.0  11322.0  \n",
      "1     1.0     0.5   6119.0  \n",
      "2     0.0    10.0   5174.0  \n",
      "3     0.0    10.0   7274.0  \n",
      "5     0.0     3.0   4078.0  \n"
     ]
    }
   ],
   "source": [
    "print(dcheck_csv.head())\n",
    "print(dcheck_sql.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle them\n",
    "dcheck_sql.to_pickle(homeDir+'DCheckSQL_FF.pkl')\n",
    "dcheck_csv.to_pickle(homeDir+'DCheckCSV_FF.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
